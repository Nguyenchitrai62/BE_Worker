import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import pickle
import os

# ==================== CONFIGURATION ====================
# Ch·ªçn strategy: 'long', 'short'
STRATEGY = 'short'  

print(f"üéØ Training strategy: {STRATEGY.upper()}")

# 1. ƒê·ªçc d·ªØ li·ªáu
df = pd.read_csv("data.csv")
df = df.dropna(subset=['price_vs_ma7', 'close/open', 'max_gain_pct', 'max_loss_pct'])

sequence_len = 15
features = ['price_vs_ma7', 'close/open']
X, y = [], []

# 2. T·∫°o chu·ªói ƒë·∫ßu v√†o theo strategy
print("üìä Creating sequences...")

def create_sequences(df, strategy):
    """
    T·∫°o sequences theo strategy
    """
    X_data, y_data = [], []
    
    for i in range(sequence_len, len(df)):
        seq = df[features].iloc[i-sequence_len:i].values
        
        if strategy == 'long' and df['signal'].iloc[i] == 1:
            # Long: signal=1, target = max_gain_pct - max_loss_pct
            target = df['max_gain_pct'].iloc[i] - df['max_loss_pct'].iloc[i]
            target = np.clip(target, -3, 3)
            X_data.append(seq)
            y_data.append(target)
            
        elif strategy == 'short' and df['signal'].iloc[i] == 0:
            # Short: signal=0, target = max_loss_pct - max_gain_pct  
            target = df['max_loss_pct'].iloc[i] - df['max_gain_pct'].iloc[i]
            target = np.clip(target, -3, 3)
            X_data.append(seq)
            y_data.append(target)
             
    return np.array(X_data), np.array(y_data)

X, y = create_sequences(df, STRATEGY)

print(f"üìä Total {STRATEGY} samples: {len(X)}")
print(f"üìä Target statistics:")
print(f"   Mean target: {np.mean(y):.4f}")
print(f"   Std target: {np.std(y):.4f}")
print(f"   Min target: {np.min(y):.4f}")
print(f"   Max target: {np.max(y):.4f}")

if len(X) == 0:
    print("‚ùå No samples found! Check your data and strategy settings.")
    exit()

# 3. Chu·∫©n h√≥a features (X)
scaler_X = StandardScaler()
X_reshaped = X.reshape(-1, X.shape[-1])
X_scaled = scaler_X.fit_transform(X_reshaped)
X_scaled = X_scaled.reshape(X.shape)

# Chu·∫©n h√≥a target (y) ƒë·ªÉ training ·ªïn ƒë·ªãnh h∆°n
scaler_y = StandardScaler()
y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

print(f"üìä After scaling:")
print(f"   X mean: {np.mean(X_scaled, axis=(0,1))}")
print(f"   X std: {np.std(X_scaled, axis=(0,1))}")
print(f"   y_scaled mean: {np.mean(y_scaled):.4f}")
print(f"   y_scaled std: {np.std(y_scaled):.4f}")

# 4. Chia train/test theo th·ªùi gian
split_index = int(len(X_scaled) * 0.8)
X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]
y_train, y_test = y_scaled[:split_index], y_scaled[split_index:]
y_test_original = y[split_index:]

print(f"üìä Train: {len(X_train)} samples")
print(f"üìä Test: {len(X_test)} samples")

# 5. Model LSTM
print(f"\nüèóÔ∏è Creating LSTM model for {STRATEGY} strategy...")

model = tf.keras.Sequential([
    tf.keras.layers.LSTM(32, input_shape=(sequence_len, len(features)), 
                        return_sequences=False, dropout=0.2, recurrent_dropout=0.1),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(8, activation='relu'),  
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1)
])

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(
    optimizer=optimizer,
    loss='mse',
    metrics=['mae']
)

print(f"\nüèóÔ∏è Model Architecture for {STRATEGY}:")
model.summary()

# 6. Callbacks
os.makedirs('models', exist_ok=True)
best_model_path = f'models/best_{STRATEGY}_model.h5'

checkpoint = tf.keras.callbacks.ModelCheckpoint(
    best_model_path,
    monitor='val_loss',
    save_best_only=True,
    mode='min',
    verbose=1
)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=10,
    min_lr=0.00001,
    verbose=1
)

# 7. Training
print(f"\nüöÄ Training {STRATEGY} model...")
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=16,
    validation_data=(X_test, y_test),
    callbacks=[checkpoint, reduce_lr],
    verbose=1
)

# 8. Load model t·ªët nh·∫•t
print(f"\nüì• Loading best {STRATEGY} model...")
best_model = tf.keras.models.load_model(best_model_path)

# 9. ƒê√°nh gi√° model
print("\n" + "="*60)
print(f"üìä {STRATEGY.upper()} MODEL EVALUATION")
print("="*60)

y_pred_scaled = best_model.predict(X_test, verbose=0).flatten()
y_pred_original = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()

mse = mean_squared_error(y_test_original, y_pred_original)
mae = mean_absolute_error(y_test_original, y_pred_original)
rmse = np.sqrt(mse)
r2 = r2_score(y_test_original, y_pred_original)

print(f"üìà {STRATEGY.upper()} Regression Metrics:")
print(f"   MSE: {mse:.6f}")
print(f"   RMSE: {rmse:.6f}")
print(f"   MAE: {mae:.6f}")
print(f"   R¬≤ Score: {r2:.4f}")

print(f"\nüìä Prediction vs Actual:")
print(f"   Actual mean: {np.mean(y_test_original):.6f}")
print(f"   Predicted mean: {np.mean(y_pred_original):.6f}")
print(f"   Actual std: {np.std(y_test_original):.6f}")
print(f"   Predicted std: {np.std(y_pred_original):.6f}")

# 10. Ph√¢n t√≠ch predictions
residuals = y_test_original - y_pred_original
print(f"\nüìä Prediction Analysis:")
print(f"   Mean residual: {np.mean(residuals):.6f}")
print(f"   Std residual: {np.std(residuals):.6f}")
print(f"   Max error: {np.max(np.abs(residuals)):.6f}")

# Top v√† bottom predictions
top_indices = np.argsort(y_pred_original)[-5:]
bottom_indices = np.argsort(y_pred_original)[:5]

print(f"\nüîù Top 5 predicted {STRATEGY} targets:")
for i, idx in enumerate(reversed(top_indices)):
    print(f"   {i+1}. Predicted: {y_pred_original[idx]:.6f}, Actual: {y_test_original[idx]:.6f}")

print(f"\nüîª Bottom 5 predicted {STRATEGY} targets:")
for i, idx in enumerate(bottom_indices):
    print(f"   {i+1}. Predicted: {y_pred_original[idx]:.6f}, Actual: {y_test_original[idx]:.6f}")

# 11. Save scalers v√† model info
scaler_X_path = f'models/{STRATEGY}_scaler_X.pkl'
scaler_y_path = f'models/{STRATEGY}_scaler_y.pkl'

with open(scaler_X_path, 'wb') as f:
    pickle.dump(scaler_X, f)

with open(scaler_y_path, 'wb') as f:
    pickle.dump(scaler_y, f)

model_info = {
    'strategy': STRATEGY,
    'sequence_len': sequence_len,
    'features': features,
    'target_formula': {
        'long': 'max_gain_pct - max_loss_pct',
        'short': 'max_loss_pct - max_gain_pct',
        'both': 'long + short combined'
    }[STRATEGY],
    'train_samples': len(X_train),
    'test_samples': len(X_test),
    'mse': float(mse),
    'mae': float(mae),
    'rmse': float(rmse),
    'r2_score': float(r2),
    'target_mean': float(np.mean(y)),
    'target_std': float(np.std(y))
}

info_path = f'models/{STRATEGY}_model_info.pkl'
with open(info_path, 'wb') as f:
    pickle.dump(model_info, f)

print(f"\nüíæ {STRATEGY.upper()} Files saved:")
print(f"   - {best_model_path}")  
print(f"   - {scaler_X_path}")
print(f"   - {scaler_y_path}")
print(f"   - {info_path}")

# 12. Production function ƒë·ªÉ predict
def predict_target(model, scaler_X, scaler_y, df_new, strategy, sequence_len=sequence_len):
    """
    D·ª± ƒëo√°n target cho strategy ƒë∆∞·ª£c ch·ªçn
    
    Args:
        model: Trained LSTM model
        scaler_X: Fitted StandardScaler for features
        scaler_y: Fitted StandardScaler for target
        df_new: DataFrame with new data
        strategy: 'long', 'short', ho·∫∑c 'both'
        sequence_len: Sequence length used in training
    
    Returns:
        DataFrame with predictions
    """
    results = []
    
    for i in range(sequence_len, len(df_new)):
        should_predict = False
        signal_type = None
        
        if strategy == 'long' and df_new['signal'].iloc[i] == 1:
            should_predict = True
            signal_type = 'long'
        elif strategy == 'short' and df_new['signal'].iloc[i] == 0:
            should_predict = True
            signal_type = 'short'
        elif strategy == 'both':
            if df_new['signal'].iloc[i] == 1:
                should_predict = True
                signal_type = 'long'
            elif df_new['signal'].iloc[i] == 0:
                should_predict = True
                signal_type = 'short'
        
        if should_predict:
            # Create sequence
            seq = df_new[features].iloc[i-sequence_len:i].values
            seq_scaled = scaler_X.transform(seq.reshape(-1, len(features))).reshape(1, sequence_len, len(features))
            
            # Predict scaled value
            pred_scaled = model.predict(seq_scaled, verbose=0)[0][0]
            
            # Convert back to original scale
            pred_original = scaler_y.inverse_transform([[pred_scaled]])[0][0]
            
            results.append({
                'index': i,
                'timestamp': df_new.index[i] if hasattr(df_new.index, 'to_list') else i,
                'signal': df_new['signal'].iloc[i],
                'signal_type': signal_type,
                'predicted_target': pred_original,
                'strategy': strategy
            })
    
    return pd.DataFrame(results)

print(f"\n‚úÖ {STRATEGY.upper()} model ready!")
print(f"üéØ Use predict_target() function for new predictions")
print(f"üìà Model performance: R¬≤ = {r2:.4f}, RMSE = {rmse:.6f}")

# 13. Training history summary
print(f"\nüìà Training History Summary:")
print(f"   Final train loss: {history.history['loss'][-1]:.6f}")
print(f"   Final val loss: {history.history['val_loss'][-1]:.6f}")
print(f"   Best val loss: {min(history.history['val_loss']):.6f}")
print(f"   Final train MAE: {history.history['mae'][-1]:.6f}")
print(f"   Final val MAE: {history.history['val_mae'][-1]:.6f}")

# 14. H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
print(f"\n" + "="*60)
print("üìã USAGE INSTRUCTIONS")
print("="*60)
print("1. ƒê·ªÉ train model LONG:")
print("   - ƒê·∫∑t STRATEGY = 'long'")
print("   - Model s·∫Ω d√πng signal=1 v√† target = max_gain_pct - max_loss_pct")
print()
print("2. ƒê·ªÉ train model SHORT:")
print("   - ƒê·∫∑t STRATEGY = 'short'") 
print("   - Model s·∫Ω d√πng signal=0 v√† target = max_loss_pct - max_gain_pct")
print()
print("3. ƒê·ªÉ train model BOTH:")
print("   - ƒê·∫∑t STRATEGY = 'both'")
print("   - Model s·∫Ω d√πng c·∫£ signal=0 v√† signal=1")
print()
print("4. Files ƒë∆∞·ª£c l∆∞u v·ªõi t√™n strategy:")
print(f"   - Model: models/best_{STRATEGY}_model.h5")
print(f"   - Scalers: models/{STRATEGY}_scaler_X.pkl, models/{STRATEGY}_scaler_y.pkl")
print(f"   - Info: models/{STRATEGY}_model_info.pkl")